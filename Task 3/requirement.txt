install python 3.6
pip install pyqt5
pip install keyboard
paste winGuiAuto.py inside sitepackages
pip install pypiwin32
pip install pyttsx3
python -m pip install tensorflow --trusted-host files.pythonhosted.org --trusted-host pypi.org --trusted-host pypi.python.org
pip install scipy
pip install opencv-python==3.4.2.16
pip install opencv-contrib-python==3.4.2.16
pip install qimage2ndarray
pip install tensorflow==2.0.0-alpha0
pip install keras (if keras doesnt work just replace keras.model to tensorflow.keras.model)
pip install pillow      

Instructions:
Getting Started
All the source code is available inside SourceCode Directory. It requires python version 3.6 or later as to synchronize with tensorflow.

winGuiAuto.py available inside source code directory contains the hwnd handler which is used to tweak the default window behavior much similar to windows programming.
The Recognise.py will recognise the gesture as per the trained dataset, recogniseAppend.py file will make a formation of sentences. These are acting as the stubs for this project. This project has been developed module wise and then has been integrated into a whole full fledge application. Long press 'escape' key for exiting a window.
gestfinal2.min.mp4 is the introductory video demonstration of the complete application. icons and UI_Files directory contains all the necessary front end assets.
Capture.py file will help in creating your own dataset and cnn_model.py file will use cnn deep neural nets to train your model and store it in the form of hadoop distributed (h5) format.
Build the model with name "ASLModel.h5" using cnn_model.py or give any name just modify the line 38 inside "Dashboard.py"
Install the required libraries and packages.
Start using the application by simply double clicking "Dashboard.py"
If you want to move the placing of the window then simply refer to the coordinates available inside cv2.moveWindow() functions.